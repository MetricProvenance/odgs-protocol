[
  {
    "metric_id": "urn:odgs:metric:edu_bias_disparate_impact",
    "name": "Student Admission Bias Ratio",
    "domain": "Admissions",
    "definition": "Measures the selection rate of a protected group vs the selection rate of the highest-performing group to detect algorithmic bias under EU AI Act Annex IV.",
    "calculation_logic": "SELECT (COUNT(CASE WHEN protected_group = 1 AND admitted = 1 THEN 1 END) / COUNT(CASE WHEN protected_group = 1 THEN 1 END)) / (NULLIF(COUNT(CASE WHEN protected_group = 0 AND admitted = 1 THEN 1 END) / COUNT(CASE WHEN protected_group = 0 THEN 1 END), 0))",
    "owner": "Office of Institutional Research",
    "compliance": {
      "ai_risk_level": "High",
      "gdpr_pii": "Sensitive",
      "data_classification": "Restricted"
    }
  },
  {
    "metric_id": "urn:odgs:metric:edu_data_completeness",
    "name": "Dataset Completeness for Grading AI",
    "domain": "Assessment",
    "definition": "Percentage of required features present in the training set for automated grading systems to ensure data quality requirements of EU AI Act Article 10.",
    "calculation_logic": "SELECT 1 - (SUM(CASE WHEN student_id IS NULL OR grade_history IS NULL THEN 1 ELSE 0 END) / COUNT(*))",
    "owner": "Data Engineering Lead",
    "compliance": {
      "ai_risk_level": "High",
      "gdpr_pii": "PII",
      "data_classification": "Confidential"
    }
  },
  {
    "metric_id": "urn:odgs:metric:edu_consent_coverage",
    "name": "AI Processing Consent Rate",
    "domain": "Privacy",
    "definition": "Proportion of students who have provided explicit consent for their data to be used in AI-based behavioral predictive modeling.",
    "calculation_logic": "SELECT COUNT(student_id) FROM consent_registry WHERE ai_processing_opt_in = TRUE / COUNT(DISTINCT student_id)",
    "owner": "Data Protection Officer",
    "compliance": {
      "ai_risk_level": "Limited",
      "gdpr_pii": "PII",
      "data_classification": "Internal"
    }
  }
]